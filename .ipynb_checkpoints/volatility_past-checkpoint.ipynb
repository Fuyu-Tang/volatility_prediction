{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Min    Open    High     Low   Close  Adj_Close     Volume\n",
      "Date                                                                   \n",
      "2006/7/3     9:31  106.95  106.95  106.95  106.95          5     5348.0\n",
      "2006/7/3     9:32  106.90  106.90  106.90  106.90         50    53450.0\n",
      "2006/7/3     9:33  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:34  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:35  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:36  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:37  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:38  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:39  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:40  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:41  106.89  106.89  106.89  106.89         10    10689.0\n",
      "2006/7/3     9:42  106.89  106.89  106.89  106.89          0        0.0\n",
      "2006/7/3     9:43  106.89  106.89  106.89  106.89          0        0.0\n",
      "2006/7/3     9:44  106.90  106.90  106.90  106.90         60    64140.0\n",
      "2006/7/3     9:45  106.95  106.95  106.95  106.95          9     9625.0\n",
      "2006/7/3     9:46  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:47  106.95  106.95  106.95  106.95         20    21390.0\n",
      "2006/7/3     9:48  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:49  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:50  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:51  106.94  106.95  106.90  106.95         71    75912.0\n",
      "2006/7/3     9:52  106.90  106.90  106.90  106.90         20    21380.0\n",
      "2006/7/3     9:53  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:54  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:55  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:56  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:57  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:58  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:59  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3    10:00  106.90  106.90  106.90  106.90          0        0.0\n",
      "...           ...     ...     ...     ...     ...        ...        ...\n",
      "2012/12/31  14:31  104.68  104.68  104.68  104.68          3     3144.0\n",
      "2012/12/31  14:32  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:33  104.70  104.70  104.70  104.70       8018  8394800.0\n",
      "2012/12/31  14:34  104.70  104.70  104.70  104.70       1244  1302464.0\n",
      "2012/12/31  14:35  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:36  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:37  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:38  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:39  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:40  104.69  104.69  104.69  104.69         10    10472.0\n",
      "2012/12/31  14:41  104.70  104.70  104.70  104.70         14    14656.0\n",
      "2012/12/31  14:42  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:43  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:44  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:45  104.68  104.68  104.68  104.68          2     2096.0\n",
      "2012/12/31  14:46  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:47  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:48  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:49  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:50  104.70  104.70  104.70  104.70       5258  5505088.0\n",
      "2012/12/31  14:51  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:52  104.56  104.56  104.56  104.56        726   759152.0\n",
      "2012/12/31  14:53  104.56  104.69  104.56  104.60        676   706832.0\n",
      "2012/12/31  14:54  104.68  104.70  104.68  104.70       4507  4718728.0\n",
      "2012/12/31  14:55  104.69  104.69  104.69  104.69         33    34544.0\n",
      "2012/12/31  14:56  104.60  104.60  104.60  104.60         42    43936.0\n",
      "2012/12/31  14:57  104.60  104.70  104.60  104.70       2040  2135616.0\n",
      "2012/12/31  14:58  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:59  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  15:00  104.69  104.69  104.69  104.69       1922  2012336.0\n",
      "\n",
      "[380640 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "df1=pd.read_csv(\"SH000300/SH000300_2009_1.csv\")\n",
    "df2=pd.read_csv(\"SH000300/SH000300_2009_2.csv\")\n",
    "df3=pd.read_csv(\"SH000300/SH000300_2010_1.csv\")\n",
    "df4=pd.read_csv(\"SH000300/SH000300_2010_2.csv\")\n",
    "df5=pd.read_csv(\"SH000300/SH000300_2011_1.csv\")\n",
    "df6=pd.read_csv(\"SH000300/SH000300_2011_2.csv\")\n",
    "df7=pd.read_csv(\"SH000300/SH000300_2012_1.csv\")\n",
    "df8=pd.read_csv(\"SH000300/SH000300_2012_2.csv\")\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],axis=0)\n",
    "\"\"\"\n",
    "df1=pd.read_csv(\"SH010107/SH010107_2006_2.csv\")\n",
    "df2=pd.read_csv(\"SH010107/SH010107_2007_1.csv\")\n",
    "df3=pd.read_csv(\"SH010107/SH010107_2007_2.csv\")\n",
    "df4=pd.read_csv(\"SH010107/SH010107_2008_1.csv\")\n",
    "df5=pd.read_csv(\"SH010107/SH010107_2008_2.csv\")\n",
    "df6=pd.read_csv(\"SH010107/SH010107_2009_1.csv\")\n",
    "df7=pd.read_csv(\"SH010107/SH010107_2009_2.csv\")\n",
    "df8=pd.read_csv(\"SH010107/SH010107_2010_1.csv\")\n",
    "df9=pd.read_csv(\"SH010107/SH010107_2010_2.csv\")\n",
    "df10=pd.read_csv(\"SH010107/SH010107_2011_1.csv\")\n",
    "df11=pd.read_csv(\"SH010107/SH010107_2011_2.csv\")\n",
    "df12=pd.read_csv(\"SH010107/SH010107_2012_1.csv\")\n",
    "df13=pd.read_csv(\"SH010107/SH010107_2012_2.csv\")\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13],axis=0)\n",
    "df=df.set_index(\"Date\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1586,)\n",
      "(1586,)\n"
     ]
    }
   ],
   "source": [
    "#获取每日最高价\n",
    "high=df[\"High\"].groupby(\"Date\").max()\n",
    "high.name=\"High\"\n",
    "print(high.shape)\n",
    "#获取每日最低价\n",
    "low=df[\"Low\"].groupby(\"Date\").min()\n",
    "low.name=\"Low\"\n",
    "print(low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以词典形式存储对应的开盘价和收盘价再转成dataframe的形式\n",
    "Open_Dict={}\n",
    "Close_Dict={}\n",
    "for name, group in df[\"Open\"].groupby(\"Date\"):\n",
    "    Open_Dict[name]=group.iloc[0]\n",
    "for name, group in df[\"Close\"].groupby(\"Date\"):\n",
    "    Close_Dict[name]=group.iloc[239]\n",
    "Open=pd.DataFrame.from_dict(Open_Dict, orient='index')\n",
    "Close=pd.DataFrame.from_dict(Close_Dict, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volatility\n",
      "Date                  \n",
      "2006/10/10    0.000104\n",
      "2006/10/11    0.000094\n",
      "2006/10/12    0.000055\n",
      "2006/10/13    0.000108\n",
      "2006/10/16    0.000112\n",
      "2006/10/17    0.000114\n",
      "2006/10/18    0.000103\n",
      "2006/10/19    0.000150\n",
      "2006/10/20    0.000125\n",
      "2006/10/23    0.000163\n",
      "2006/10/24    0.000164\n",
      "2006/10/25    0.000141\n",
      "2006/10/26    0.000149\n",
      "2006/10/27    0.000158\n",
      "2006/10/30    0.000074\n",
      "2006/10/31    0.000194\n",
      "2006/10/9     0.000198\n",
      "2006/11/1     0.000060\n",
      "2006/11/10    0.000164\n",
      "2006/11/13    0.000145\n",
      "2006/11/14    0.000443\n",
      "2006/11/15    0.000031\n",
      "2006/11/16    0.000096\n",
      "2006/11/17    0.000054\n",
      "2006/11/2     0.000070\n",
      "2006/11/20    0.000050\n",
      "2006/11/21    0.000161\n",
      "2006/11/22    0.000153\n",
      "2006/11/23    0.000165\n",
      "2006/11/24    0.000153\n",
      "...                ...\n",
      "2012/8/27     0.000176\n",
      "2012/8/28     0.000160\n",
      "2012/8/29     0.000293\n",
      "2012/8/3      0.000163\n",
      "2012/8/30     0.000195\n",
      "2012/8/31     0.000123\n",
      "2012/8/6      0.000235\n",
      "2012/8/7      0.000208\n",
      "2012/8/8      0.000162\n",
      "2012/8/9      0.000245\n",
      "2012/9/10     0.000127\n",
      "2012/9/11     0.000087\n",
      "2012/9/12     0.000358\n",
      "2012/9/13     0.000373\n",
      "2012/9/14     0.000214\n",
      "2012/9/17     0.000135\n",
      "2012/9/18     0.000179\n",
      "2012/9/19     0.000174\n",
      "2012/9/20     0.000146\n",
      "2012/9/21     0.000148\n",
      "2012/9/24     0.000156\n",
      "2012/9/25     0.000188\n",
      "2012/9/26     0.000277\n",
      "2012/9/27     0.000228\n",
      "2012/9/28     0.000254\n",
      "2012/9/3      0.000129\n",
      "2012/9/4      0.000085\n",
      "2012/9/5      0.000108\n",
      "2012/9/6      0.000123\n",
      "2012/9/7      0.000332\n",
      "\n",
      "[1586 rows x 1 columns]\n",
      "            volatility\n",
      "Date                  \n",
      "2006/10/10   -0.783924\n",
      "2006/10/11   -1.054846\n",
      "2006/10/12   -0.686646\n",
      "2006/10/13   -0.664823\n",
      "2006/10/16   -0.645416\n",
      "2006/10/17   -0.722115\n",
      "2006/10/18   -0.395568\n",
      "2006/10/19   -0.574610\n",
      "2006/10/20   -0.311133\n",
      "2006/10/23   -0.302966\n",
      "2006/10/24   -0.464362\n",
      "2006/10/25   -0.409000\n",
      "2006/10/26   -0.342987\n",
      "2006/10/27   -0.924161\n",
      "2006/10/30   -0.094060\n",
      "2006/10/31   -0.065479\n",
      "2006/10/9    -1.023486\n",
      "2006/11/1    -0.300604\n",
      "2006/11/10   -0.432549\n",
      "2006/11/13    1.626375\n",
      "2006/11/14   -1.221546\n",
      "2006/11/15   -0.770251\n",
      "2006/11/16   -1.061503\n",
      "2006/11/17   -0.949448\n",
      "2006/11/2    -1.091370\n",
      "2006/11/20   -0.324546\n",
      "2006/11/21   -0.376349\n",
      "2006/11/22   -0.295854\n",
      "2006/11/23   -0.380000\n",
      "2006/11/24    0.862628\n",
      "...                ...\n",
      "2012/8/24    -0.221484\n",
      "2012/8/27    -0.327246\n",
      "2012/8/28     0.593932\n",
      "2012/8/29    -0.310980\n",
      "2012/8/3     -0.084534\n",
      "2012/8/30    -0.585010\n",
      "2012/8/31     0.188405\n",
      "2012/8/6      0.002862\n",
      "2012/8/7     -0.313502\n",
      "2012/8/8      0.259767\n",
      "2012/8/9     -0.559241\n",
      "2012/9/10    -0.836180\n",
      "2012/9/11     1.043564\n",
      "2012/9/12     1.144761\n",
      "2012/9/13     0.046625\n",
      "2012/9/14    -0.500819\n",
      "2012/9/17    -0.199634\n",
      "2012/9/18    -0.230512\n",
      "2012/9/19    -0.428501\n",
      "2012/9/20    -0.410009\n",
      "2012/9/21    -0.357329\n",
      "2012/9/24    -0.138418\n",
      "2012/9/25     0.482436\n",
      "2012/9/26     0.142731\n",
      "2012/9/27     0.319721\n",
      "2012/9/28    -0.546733\n",
      "2012/9/3     -0.850994\n",
      "2012/9/4     -0.688218\n",
      "2012/9/5     -0.586617\n",
      "2012/9/6      0.860168\n",
      "\n",
      "[1585 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#获取日波动率——以DataFrame的格式\n",
    "returns=df[\"Close\"].pct_change()\n",
    "volatility=returns.groupby(\"Date\").std().to_frame()\n",
    "volatility.columns=[\"volatility\"]\n",
    "print(volatility)\n",
    "volatility.head()\n",
    "lookahead_volatility=volatility.shift(-1).dropna()\n",
    "normed_label=lookahead_volatility.apply(lambda x:(x-np.mean(x))/np.std(x))\n",
    "print(normed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low   Close  today_volatility\n",
      "Date                                                        \n",
      "2006/10/10  109.05  109.30  109.02  109.30          0.000104\n",
      "2006/10/11  109.19  109.34  109.19  109.30          0.000094\n",
      "2006/10/12  109.25  109.27  109.21  109.25          0.000055\n",
      "2006/10/13  109.25  109.30  109.16  109.26          0.000108\n",
      "2006/10/16  109.26  109.31  109.19  109.31          0.000112\n",
      "2006/10/17  109.34  109.65  109.30  109.54          0.000114\n",
      "2006/10/18  109.50  109.79  109.50  109.74          0.000103\n",
      "2006/10/19  109.70  110.08  109.60  110.06          0.000150\n",
      "2006/10/20  110.00  110.30  110.00  110.26          0.000125\n",
      "2006/10/23  110.10  110.24  110.01  110.02          0.000163\n",
      "2006/10/24  110.00  110.13  109.81  110.08          0.000164\n",
      "2006/10/25  111.00  111.00  110.03  110.12          0.000141\n",
      "2006/10/26  110.10  110.20  110.00  110.19          0.000149\n",
      "2006/10/27  110.10  110.18  109.81  109.99          0.000158\n",
      "2006/10/30  109.99  109.99  109.83  109.88          0.000074\n",
      "2006/10/31  109.87  109.87  109.57  109.86          0.000194\n",
      "2006/10/9   109.35  109.35  109.00  109.11          0.000198\n",
      "2006/11/1   109.81  109.85  109.76  109.79          0.000060\n",
      "2006/11/10  109.72  109.95  109.72  109.94          0.000164\n",
      "2006/11/13  109.73  109.92  109.73  109.90          0.000145\n",
      "2006/11/14  110.30  110.30  109.80  109.90          0.000443\n",
      "2006/11/15  109.91  109.95  109.91  109.94          0.000031\n",
      "2006/11/16  109.90  109.98  109.90  109.92          0.000096\n",
      "2006/11/17  109.91  110.00  109.90  109.95          0.000054\n",
      "2006/11/2   109.70  109.77  109.70  109.72          0.000070\n",
      "2006/11/20  109.95  110.00  109.95  109.95          0.000050\n",
      "2006/11/21  109.90  109.97  109.67  109.96          0.000161\n",
      "2006/11/22  109.75  109.96  109.75  109.96          0.000153\n",
      "2006/11/23  109.79  109.85  109.75  109.81          0.000165\n",
      "2006/11/24  109.80  109.83  109.50  109.70          0.000153\n",
      "...            ...     ...     ...     ...               ...\n",
      "2012/8/27   106.70  106.94  106.70  106.94          0.000176\n",
      "2012/8/28   106.94  107.00  106.76  106.90          0.000160\n",
      "2012/8/29   106.82  106.85  106.51  106.80          0.000293\n",
      "2012/8/3    107.65  107.65  107.42  107.48          0.000163\n",
      "2012/8/30   106.70  106.85  106.65  106.85          0.000195\n",
      "2012/8/31   106.72  106.85  106.72  106.84          0.000123\n",
      "2012/8/6    107.37  107.46  107.10  107.13          0.000235\n",
      "2012/8/7    107.24  107.26  106.91  106.95          0.000208\n",
      "2012/8/8    106.80  107.00  106.80  106.93          0.000162\n",
      "2012/8/9    106.66  107.15  106.66  107.06          0.000245\n",
      "2012/9/10   106.55  106.64  106.45  106.52          0.000127\n",
      "2012/9/11   106.45  106.51  106.35  106.37          0.000087\n",
      "2012/9/12   106.45  106.45  106.03  106.14          0.000358\n",
      "2012/9/13   106.34  106.34  106.00  106.06          0.000373\n",
      "2012/9/14   106.04  106.04  105.65  105.75          0.000214\n",
      "2012/9/17   105.73  105.73  105.45  105.59          0.000135\n",
      "2012/9/18   105.46  105.76  105.41  105.75          0.000179\n",
      "2012/9/19   105.75  105.80  105.65  105.69          0.000174\n",
      "2012/9/20   105.66  105.79  105.65  105.68          0.000146\n",
      "2012/9/21   105.67  106.09  105.67  106.09          0.000148\n",
      "2012/9/24   105.90  105.97  105.79  105.95          0.000156\n",
      "2012/9/25   105.86  106.20  105.70  106.19          0.000188\n",
      "2012/9/26   106.29  106.45  106.11  106.40          0.000277\n",
      "2012/9/27   106.40  106.40  106.00  106.30          0.000228\n",
      "2012/9/28   106.21  106.45  106.21  106.43          0.000254\n",
      "2012/9/3    106.70  106.80  106.66  106.75          0.000129\n",
      "2012/9/4    106.80  106.99  106.80  106.99          0.000085\n",
      "2012/9/5    106.98  106.98  106.75  106.80          0.000108\n",
      "2012/9/6    106.75  106.80  106.70  106.79          0.000123\n",
      "2012/9/7    106.65  106.79  106.21  106.63          0.000332\n",
      "\n",
      "[1586 rows x 5 columns]\n",
      "                Open      High       Low     Close  today_volatility\n",
      "Date                                                                \n",
      "2006/10/10  1.186971  1.207550  1.220619  1.242079         -0.714819\n",
      "2006/10/11  1.223312  1.217945  1.264829  1.242079         -0.783594\n",
      "2006/10/12  1.238887  1.199753  1.270031  1.229082         -1.054558\n",
      "2006/10/13  1.238887  1.207550  1.257028  1.231682         -0.686301\n",
      "2006/10/16  1.241483  1.210149  1.264829  1.244678         -0.664475\n",
      "2006/10/17  1.262249  1.298513  1.293436  1.304463         -0.645064\n",
      "2006/10/18  1.303782  1.334898  1.345448  1.356450         -0.721776\n",
      "2006/10/19  1.355698  1.410267  1.371454  1.439629         -0.395178\n",
      "2006/10/20  1.433571  1.467444  1.475478  1.491615         -0.574248\n",
      "2006/10/23  1.459529  1.451851  1.478078  1.429231         -0.310730\n",
      "2006/10/24  1.433571  1.423262  1.426066  1.444827         -0.302562\n",
      "2006/10/25  1.693150  1.649370  1.483280  1.455225         -0.463982\n",
      "2006/10/26  1.459529  1.441455  1.475478  1.473420         -0.408612\n",
      "2006/10/27  1.459529  1.436257  1.426066  1.421433         -0.342589\n",
      "2006/10/30  1.430975  1.386877  1.431268  1.392841         -0.923853\n",
      "2006/10/31  1.399826  1.355690  1.363652  1.387642         -0.093623\n",
      "2006/10/9   1.264845  1.220544  1.215418  1.192691         -0.065038\n",
      "2006/11/1   1.384251  1.350492  1.413063  1.369446         -1.023192\n",
      "2006/11/10  1.360889  1.376481  1.402661  1.408437         -0.300199\n",
      "2006/11/13  1.363485  1.368684  1.405262  1.398039         -0.432165\n",
      "2006/11/14  1.511445  1.467444  1.423466  1.398039          1.627077\n",
      "2006/11/15  1.410209  1.376481  1.452072  1.408437         -1.221283\n",
      "2006/11/16  1.407613  1.384278  1.449472  1.403238         -0.769918\n",
      "2006/11/17  1.410209  1.389476  1.449472  1.411036         -1.061215\n",
      "2006/11/2   1.355698  1.329700  1.397460  1.351251         -0.949143\n",
      "2006/11/20  1.420592  1.389476  1.462475  1.411036         -1.091087\n",
      "2006/11/21  1.407613  1.381679  1.389658  1.413635         -0.324145\n",
      "2006/11/22  1.368676  1.379080  1.410463  1.413635         -0.375956\n",
      "2006/11/23  1.379060  1.350492  1.410463  1.374645         -0.295448\n",
      "2006/11/24  1.381655  1.345294  1.345448  1.346052         -0.379607\n",
      "...              ...       ...       ...       ...               ...\n",
      "2012/8/27   0.576961  0.594198  0.617281  0.628635         -0.221068\n",
      "2012/8/28   0.639260  0.609792  0.632885  0.618238         -0.326846\n",
      "2012/8/29   0.608110  0.570808  0.567870  0.592244          0.594474\n",
      "2012/8/3    0.823561  0.778724  0.804524  0.768999         -0.310577\n",
      "2012/8/30   0.576961  0.570808  0.604278  0.605241         -0.084096\n",
      "2012/8/31   0.582152  0.570808  0.622482  0.602642         -0.584649\n",
      "2012/8/6    0.750879  0.729344  0.721305  0.678022          0.188885\n",
      "2012/8/7    0.717133  0.677365  0.671893  0.631234          0.003313\n",
      "2012/8/8    0.602919  0.609792  0.643287  0.626036         -0.313100\n",
      "2012/8/9    0.566578  0.648776  0.606879  0.659827          0.260258\n",
      "2012/9/10   0.538024  0.516230  0.552266  0.519463         -0.558876\n",
      "2012/9/11   0.512066  0.482444  0.526260  0.480473         -0.835858\n",
      "2012/9/12   0.512066  0.466850  0.443041  0.420688          1.044176\n",
      "2012/9/13   0.483512  0.438262  0.435239  0.399893          1.145389\n",
      "2012/9/14   0.405639  0.360293  0.344218  0.319314          0.047084\n",
      "2012/9/17   0.325169  0.279726  0.292206  0.277724         -0.500445\n",
      "2012/9/18   0.255083  0.287523  0.281804  0.319314         -0.199214\n",
      "2012/9/19   0.330361  0.297919  0.344218  0.303718         -0.230097\n",
      "2012/9/20   0.306999  0.295320  0.344218  0.301118         -0.428116\n",
      "2012/9/21   0.309595  0.373288  0.349419  0.407691         -0.409621\n",
      "2012/9/24   0.369298  0.342101  0.380627  0.371301         -0.356933\n",
      "2012/9/25   0.358915  0.401876  0.357221  0.433685         -0.137989\n",
      "2012/9/26   0.470533  0.466850  0.463846  0.488271          0.482961\n",
      "2012/9/27   0.499087  0.453855  0.435239  0.462277          0.143204\n",
      "2012/9/28   0.449767  0.466850  0.489852  0.496069          0.320221\n",
      "2012/9/3    0.576961  0.557813  0.606879  0.579248         -0.546367\n",
      "2012/9/4    0.602919  0.607193  0.643287  0.641632         -0.850674\n",
      "2012/9/5    0.649643  0.604594  0.630284  0.592244         -0.687873\n",
      "2012/9/6    0.589940  0.557813  0.617281  0.589645         -0.586256\n",
      "2012/9/7    0.563982  0.555214  0.489852  0.548056          0.860752\n",
      "\n",
      "[1586 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#这里形成的历史数据和前面需要的训练数据不同。这里形成的是每日的价格和对应的波动率。\n",
    "history_data=pd.concat([Open,high,low,Close,volatility],axis=1)\n",
    "history_data.columns=['Open','High','Low','Close','today_volatility']\n",
    "print(history_data)\n",
    "history=history_data[[\"Open\",\"High\",\"Low\",\"Close\",\"today_volatility\"]].apply(lambda x:(x-np.mean(x))/np.std(x))\n",
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1424, 2, 5)\n",
      "(1, 2, 5)\n"
     ]
    }
   ],
   "source": [
    "def get_predict_data(X,LOOKBACK_WINDOW):\n",
    "    cur_X=[]\n",
    "    _Xs=[]\n",
    "    for i in range(X.shape[0]-LOOKBACK_WINDOW,X.shape[0],1):\n",
    "        cur_X.append(X.values[i])\n",
    "    _Xs.append(cur_X)\n",
    "    return np.array(_Xs)\n",
    "\n",
    "        \n",
    "def normalize_data(X,Y,LOOKBACK_WINDOW):\n",
    "    _Xs=[]\n",
    "    _Ys=[]\n",
    "    for i in range(X.shape[0]-LOOKBACK_WINDOW):\n",
    "        cur_X=X.values[i:i+LOOKBACK_WINDOW]#_Xs中的每一个元素都是由过去n天数据的时间序列组成的。\n",
    "        #每个sample的数据是以一个序列的形式输入的。\n",
    "        _Xs.append(cur_X)\n",
    "        \n",
    "        y_pointer=i+LOOKBACK_WINDOW#在循环中减去了所以要加回来。\n",
    "        cur_Y=Y.values[y_pointer]\n",
    "        _Ys.append(cur_Y)\n",
    "    return np.array(_Xs), np.array(_Ys)#转成数组形式\n",
    "\n",
    "data_drop=history.drop([\"2012/9/7\"])\n",
    "#print(data_drop)\n",
    "x,y=normalize_data(data_drop,normed_label,2)\n",
    "x_train, x_test=x[:int(len(x) * .9)],x[int(len(x) * .9):]\n",
    "y_train, y_test=y[:int(len(y) * .9)],y[int(len(y) * .9):]\n",
    "print(x_train.shape)\n",
    "#print(x_test)\n",
    "x_unknown=get_predict_data(data_drop,2)\n",
    "print(x_unknown.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Permute, RepeatVector\n",
    "from keras.layers import Merge, Input, concatenate\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, AtrousConvolution1D\n",
    "from keras.layers.pooling import AveragePooling1D, MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "from keras.constraints import *\n",
    "from keras import regularizers\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立模型\n",
    "d= .5\n",
    "_data_shape = (2, 5)#这里是用来在初始化input_shape的时候需要的时间间隔*特征维数\n",
    "\n",
    "#keras的核心就是在一个简单模型的基础上加层数。\n",
    "model = Sequential()\n",
    "\n",
    "#指出用LSTM模型，隐藏层有128个神经元,比如我们把64维词向量转化为128维词向量。return_sequences如果true表示返回(samples, timesteps, output_dim)的\n",
    "#3D张量，否则返回(samples, output_dim)的2D张量。\n",
    "\n",
    "model.add(LSTM(128, input_shape=_data_shape, return_sequences=False))\n",
    "model.add(Dropout(d))#d=0.5前面指出了\n",
    "model.add(Dense(16, kernel_initializer=('uniform'),activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='tanh'))\n",
    "\n",
    "opt=Nadam(lr=0.02, clipnorm= .1)\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "#存储模型\n",
    "checkpointer=ModelCheckpoint(monitor='val_loss', filepath='/Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5',verbose=1, save_best_only=True)\n",
    "#训练模型\n",
    "model.compile(optimizer=opt, loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1281 samples, validate on 143 samples\n",
      "Epoch 1/20\n",
      " 960/1281 [=====================>........] - ETA: 0s - loss: 1.1006Epoch 00001: val_loss improved from inf to 0.45924, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 2s 1ms/step - loss: 1.0195 - val_loss: 0.4592\n",
      "Epoch 2/20\n",
      " 960/1281 [=====================>........] - ETA: 0s - loss: 0.9131Epoch 00002: val_loss improved from 0.45924 to 0.44249, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 0s 142us/step - loss: 0.9887 - val_loss: 0.4425\n",
      "Epoch 3/20\n",
      " 900/1281 [====================>.........] - ETA: 0s - loss: 0.9328Epoch 00003: val_loss improved from 0.44249 to 0.43750, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 0s 146us/step - loss: 0.9857 - val_loss: 0.4375\n",
      "Epoch 4/20\n",
      " 960/1281 [=====================>........] - ETA: 0s - loss: 0.9324Epoch 00004: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 132us/step - loss: 0.9684 - val_loss: 0.4393\n",
      "Epoch 5/20\n",
      " 900/1281 [====================>.........] - ETA: 0s - loss: 0.8534Epoch 00005: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 133us/step - loss: 0.9674 - val_loss: 0.4918\n",
      "Epoch 6/20\n",
      "1020/1281 [======================>.......] - ETA: 0s - loss: 0.9236Epoch 00006: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 125us/step - loss: 0.9593 - val_loss: 0.4469\n",
      "Epoch 7/20\n",
      " 900/1281 [====================>.........] - ETA: 0s - loss: 1.0067Epoch 00007: val_loss improved from 0.43750 to 0.42751, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 0s 147us/step - loss: 0.9527 - val_loss: 0.4275\n",
      "Epoch 8/20\n",
      "1020/1281 [======================>.......] - ETA: 0s - loss: 0.8758Epoch 00008: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 116us/step - loss: 0.9521 - val_loss: 0.4920\n",
      "Epoch 9/20\n",
      "1200/1281 [===========================>..] - ETA: 0s - loss: 0.9647Epoch 00009: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 156us/step - loss: 0.9640 - val_loss: 0.4666\n",
      "Epoch 10/20\n",
      " 960/1281 [=====================>........] - ETA: 0s - loss: 0.9511Epoch 00010: val_loss improved from 0.42751 to 0.42375, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 0s 152us/step - loss: 0.9525 - val_loss: 0.4237\n",
      "Epoch 11/20\n",
      " 900/1281 [====================>.........] - ETA: 0s - loss: 0.9675Epoch 00011: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 143us/step - loss: 0.9644 - val_loss: 0.4693\n",
      "Epoch 12/20\n",
      "1140/1281 [=========================>....] - ETA: 0s - loss: 0.9461Epoch 00012: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 160us/step - loss: 0.9574 - val_loss: 0.4703\n",
      "Epoch 13/20\n",
      "1200/1281 [===========================>..] - ETA: 0s - loss: 0.9275Epoch 00013: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 153us/step - loss: 0.9479 - val_loss: 0.4447\n",
      "Epoch 14/20\n",
      "1260/1281 [============================>.] - ETA: 0s - loss: 0.9563Epoch 00014: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 151us/step - loss: 0.9472 - val_loss: 0.4386\n",
      "Epoch 15/20\n",
      "1140/1281 [=========================>....] - ETA: 0s - loss: 0.9869Epoch 00015: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 161us/step - loss: 0.9540 - val_loss: 0.4338\n",
      "Epoch 16/20\n",
      "1080/1281 [========================>.....] - ETA: 0s - loss: 0.9970Epoch 00016: val_loss improved from 0.42375 to 0.41574, saving model to /Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\n",
      "1281/1281 [==============================] - 0s 188us/step - loss: 0.9247 - val_loss: 0.4157\n",
      "Epoch 17/20\n",
      "1260/1281 [============================>.] - ETA: 0s - loss: 0.9367Epoch 00017: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 147us/step - loss: 0.9318 - val_loss: 0.4383\n",
      "Epoch 18/20\n",
      "1200/1281 [===========================>..] - ETA: 0s - loss: 0.9738Epoch 00018: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 159us/step - loss: 0.9472 - val_loss: 0.4661\n",
      "Epoch 19/20\n",
      "1260/1281 [============================>.] - ETA: 0s - loss: 0.9265Epoch 00019: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 156us/step - loss: 0.9371 - val_loss: 0.4557\n",
      "Epoch 20/20\n",
      "1260/1281 [============================>.] - ETA: 0s - loss: 0.9373Epoch 00020: val_loss did not improve\n",
      "1281/1281 [==============================] - 0s 214us/step - loss: 0.9292 - val_loss: 0.4374\n"
     ]
    }
   ],
   "source": [
    "#model_fit是正式开始迭代数据\n",
    "history=model.fit(\n",
    "    x_train,#data\n",
    "    y_train,#labels\n",
    "    batch_size=60,#是批梯度下降和随机梯度下降的折中方法，将样本数据分为若干批。batch_size是个数。\n",
    "    epochs=20,#样本中的所有数据被计算一次就是一个epochs\n",
    "    validation_split=0.1,\n",
    "    callbacks=[reduce_lr,checkpointer],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型预测\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "model.load_weights(\"/Users/tangfuyu/Desktop/code/volatility/model_save2/model_returns.hdf5\")\n",
    "y_pred=model.predict(x_test)\n",
    "pred_df = pd.DataFrame(np.column_stack([y_test, y_pred]),columns=[\"y_test\",\"y_pred\"])\n",
    "print(pred_df)\n",
    "pred_df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate VaR\n",
    "y_unknown=model.predict(x_unknown)\n",
    "print(y_unknown)\n",
    "predict_v=y_unknown[0][0]*np.std(lookahead_volatility)+np.mean(lookahead_volatility)\n",
    "print(predict_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store predict_v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
