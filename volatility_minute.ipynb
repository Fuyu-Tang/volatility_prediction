{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Min    Open    High     Low   Close  Adj_Close     Volume\n",
      "Date                                                                   \n",
      "2006/7/3     9:31  106.95  106.95  106.95  106.95          5     5348.0\n",
      "2006/7/3     9:32  106.90  106.90  106.90  106.90         50    53450.0\n",
      "2006/7/3     9:33  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:34  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:35  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:36  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:37  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:38  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:39  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:40  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:41  106.89  106.89  106.89  106.89         10    10689.0\n",
      "2006/7/3     9:42  106.89  106.89  106.89  106.89          0        0.0\n",
      "2006/7/3     9:43  106.89  106.89  106.89  106.89          0        0.0\n",
      "2006/7/3     9:44  106.90  106.90  106.90  106.90         60    64140.0\n",
      "2006/7/3     9:45  106.95  106.95  106.95  106.95          9     9625.0\n",
      "2006/7/3     9:46  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:47  106.95  106.95  106.95  106.95         20    21390.0\n",
      "2006/7/3     9:48  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:49  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:50  106.95  106.95  106.95  106.95          0        0.0\n",
      "2006/7/3     9:51  106.94  106.95  106.90  106.95         71    75912.0\n",
      "2006/7/3     9:52  106.90  106.90  106.90  106.90         20    21380.0\n",
      "2006/7/3     9:53  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:54  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:55  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:56  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:57  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:58  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3     9:59  106.90  106.90  106.90  106.90          0        0.0\n",
      "2006/7/3    10:00  106.90  106.90  106.90  106.90          0        0.0\n",
      "...           ...     ...     ...     ...     ...        ...        ...\n",
      "2012/12/31  14:31  104.68  104.68  104.68  104.68          3     3144.0\n",
      "2012/12/31  14:32  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:33  104.70  104.70  104.70  104.70       8018  8394800.0\n",
      "2012/12/31  14:34  104.70  104.70  104.70  104.70       1244  1302464.0\n",
      "2012/12/31  14:35  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:36  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:37  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:38  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:39  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:40  104.69  104.69  104.69  104.69         10    10472.0\n",
      "2012/12/31  14:41  104.70  104.70  104.70  104.70         14    14656.0\n",
      "2012/12/31  14:42  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:43  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:44  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:45  104.68  104.68  104.68  104.68          2     2096.0\n",
      "2012/12/31  14:46  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:47  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:48  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:49  104.68  104.68  104.68  104.68          0        0.0\n",
      "2012/12/31  14:50  104.70  104.70  104.70  104.70       5258  5505088.0\n",
      "2012/12/31  14:51  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:52  104.56  104.56  104.56  104.56        726   759152.0\n",
      "2012/12/31  14:53  104.56  104.69  104.56  104.60        676   706832.0\n",
      "2012/12/31  14:54  104.68  104.70  104.68  104.70       4507  4718728.0\n",
      "2012/12/31  14:55  104.69  104.69  104.69  104.69         33    34544.0\n",
      "2012/12/31  14:56  104.60  104.60  104.60  104.60         42    43936.0\n",
      "2012/12/31  14:57  104.60  104.70  104.60  104.70       2040  2135616.0\n",
      "2012/12/31  14:58  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  14:59  104.70  104.70  104.70  104.70          0        0.0\n",
      "2012/12/31  15:00  104.69  104.69  104.69  104.69       1922  2012336.0\n",
      "\n",
      "[380640 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "df1=pd.read_csv(\"SH000300/SH000300_2009_1.csv\")\n",
    "df2=pd.read_csv(\"SH000300/SH000300_2009_2.csv\")\n",
    "df3=pd.read_csv(\"SH000300/SH000300_2010_1.csv\")\n",
    "df4=pd.read_csv(\"SH000300/SH000300_2010_2.csv\")\n",
    "df5=pd.read_csv(\"SH000300/SH000300_2011_1.csv\")\n",
    "df6=pd.read_csv(\"SH000300/SH000300_2011_2.csv\")\n",
    "df7=pd.read_csv(\"SH000300/SH000300_2012_1.csv\")\n",
    "df8=pd.read_csv(\"SH000300/SH000300_2012_2.csv\")\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],axis=0)\n",
    "\"\"\"\n",
    "df1=pd.read_csv(\"SH010107/SH010107_2006_2.csv\")\n",
    "df2=pd.read_csv(\"SH010107/SH010107_2007_1.csv\")\n",
    "df3=pd.read_csv(\"SH010107/SH010107_2007_2.csv\")\n",
    "df4=pd.read_csv(\"SH010107/SH010107_2008_1.csv\")\n",
    "df5=pd.read_csv(\"SH010107/SH010107_2008_2.csv\")\n",
    "df6=pd.read_csv(\"SH010107/SH010107_2009_1.csv\")\n",
    "df7=pd.read_csv(\"SH010107/SH010107_2009_2.csv\")\n",
    "df8=pd.read_csv(\"SH010107/SH010107_2010_1.csv\")\n",
    "df9=pd.read_csv(\"SH010107/SH010107_2010_2.csv\")\n",
    "df10=pd.read_csv(\"SH010107/SH010107_2011_1.csv\")\n",
    "df11=pd.read_csv(\"SH010107/SH010107_2011_2.csv\")\n",
    "df12=pd.read_csv(\"SH010107/SH010107_2012_1.csv\")\n",
    "df13=pd.read_csv(\"SH010107/SH010107_2012_2.csv\")\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13],axis=0)\n",
    "df=df.set_index(\"Date\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2006/10/10    0.000104\n",
      "2006/10/11    0.000094\n",
      "2006/10/12    0.000055\n",
      "2006/10/13    0.000108\n",
      "2006/10/16    0.000112\n",
      "2006/10/17    0.000114\n",
      "2006/10/18    0.000103\n",
      "2006/10/19    0.000150\n",
      "2006/10/20    0.000125\n",
      "2006/10/23    0.000163\n",
      "2006/10/24    0.000164\n",
      "2006/10/25    0.000141\n",
      "2006/10/26    0.000149\n",
      "2006/10/27    0.000158\n",
      "2006/10/30    0.000074\n",
      "2006/10/31    0.000194\n",
      "2006/10/9     0.000198\n",
      "2006/11/1     0.000060\n",
      "2006/11/10    0.000164\n",
      "2006/11/13    0.000145\n",
      "2006/11/14    0.000443\n",
      "2006/11/15    0.000031\n",
      "2006/11/16    0.000096\n",
      "2006/11/17    0.000054\n",
      "2006/11/2     0.000070\n",
      "2006/11/20    0.000050\n",
      "2006/11/21    0.000161\n",
      "2006/11/22    0.000153\n",
      "2006/11/23    0.000165\n",
      "2006/11/24    0.000153\n",
      "                ...   \n",
      "2012/8/27     0.000176\n",
      "2012/8/28     0.000160\n",
      "2012/8/29     0.000293\n",
      "2012/8/3      0.000163\n",
      "2012/8/30     0.000195\n",
      "2012/8/31     0.000123\n",
      "2012/8/6      0.000235\n",
      "2012/8/7      0.000208\n",
      "2012/8/8      0.000162\n",
      "2012/8/9      0.000245\n",
      "2012/9/10     0.000127\n",
      "2012/9/11     0.000087\n",
      "2012/9/12     0.000358\n",
      "2012/9/13     0.000373\n",
      "2012/9/14     0.000214\n",
      "2012/9/17     0.000135\n",
      "2012/9/18     0.000179\n",
      "2012/9/19     0.000174\n",
      "2012/9/20     0.000146\n",
      "2012/9/21     0.000148\n",
      "2012/9/24     0.000156\n",
      "2012/9/25     0.000188\n",
      "2012/9/26     0.000277\n",
      "2012/9/27     0.000228\n",
      "2012/9/28     0.000254\n",
      "2012/9/3      0.000129\n",
      "2012/9/4      0.000085\n",
      "2012/9/5      0.000108\n",
      "2012/9/6      0.000123\n",
      "2012/9/7      0.000332\n",
      "Name: volatility, Length: 1586, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#获取日波动率——以DataFrame的格式\n",
    "returns=df[\"Close\"].pct_change()\n",
    "volatility=returns.groupby(\"Date\").std()\n",
    "volatility.name=\"volatility\"\n",
    "print(volatility)\n",
    "volatility.head()\n",
    "lookahead_volatility=volatility.shift(-1).dropna()\n",
    "#print(lookahead_volatility)#这才是每天对应的下一天的预测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2006/10/10   -0.783924\n",
      "2006/10/11   -1.054846\n",
      "2006/10/12   -0.686646\n",
      "2006/10/13   -0.664823\n",
      "2006/10/16   -0.645416\n",
      "2006/10/17   -0.722115\n",
      "2006/10/18   -0.395568\n",
      "2006/10/19   -0.574610\n",
      "2006/10/20   -0.311133\n",
      "2006/10/23   -0.302966\n",
      "2006/10/24   -0.464362\n",
      "2006/10/25   -0.409000\n",
      "2006/10/26   -0.342987\n",
      "2006/10/27   -0.924161\n",
      "2006/10/30   -0.094060\n",
      "2006/10/31   -0.065479\n",
      "2006/10/9    -1.023486\n",
      "2006/11/1    -0.300604\n",
      "2006/11/10   -0.432549\n",
      "2006/11/13    1.626375\n",
      "2006/11/14   -1.221546\n",
      "2006/11/15   -0.770251\n",
      "2006/11/16   -1.061503\n",
      "2006/11/17   -0.949448\n",
      "2006/11/2    -1.091370\n",
      "2006/11/20   -0.324546\n",
      "2006/11/21   -0.376349\n",
      "2006/11/22   -0.295854\n",
      "2006/11/23   -0.380000\n",
      "2006/11/24    0.862628\n",
      "                ...   \n",
      "2012/8/24    -0.221484\n",
      "2012/8/27    -0.327246\n",
      "2012/8/28     0.593932\n",
      "2012/8/29    -0.310980\n",
      "2012/8/3     -0.084534\n",
      "2012/8/30    -0.585010\n",
      "2012/8/31     0.188405\n",
      "2012/8/6      0.002862\n",
      "2012/8/7     -0.313502\n",
      "2012/8/8      0.259767\n",
      "2012/8/9     -0.559241\n",
      "2012/9/10    -0.836180\n",
      "2012/9/11     1.043564\n",
      "2012/9/12     1.144761\n",
      "2012/9/13     0.046625\n",
      "2012/9/14    -0.500819\n",
      "2012/9/17    -0.199634\n",
      "2012/9/18    -0.230512\n",
      "2012/9/19    -0.428501\n",
      "2012/9/20    -0.410009\n",
      "2012/9/21    -0.357329\n",
      "2012/9/24    -0.138418\n",
      "2012/9/25     0.482436\n",
      "2012/9/26     0.142731\n",
      "2012/9/27     0.319721\n",
      "2012/9/28    -0.546733\n",
      "2012/9/3     -0.850994\n",
      "2012/9/4     -0.688218\n",
      "2012/9/5     -0.586617\n",
      "2012/9/6      0.860168\n",
      "Name: volatility, Length: 1585, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#后面思考这个标准化到底需不需要\n",
    "norm_data=df[[\"Open\",\"High\",\"Low\",\"Close\"]].apply(lambda x:(x-np.mean(x))/(np.std(x)))\n",
    "#norm_data=df[[\"Open\",\"High\",\"Low\",\"Close\"]].apply(lambda x:(x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "#波动率标签先暂时不进行[0,1]\n",
    "Group_data=norm_data[[\"Open\",\"High\",\"Low\",\"Close\"]].groupby(\"Date\")\n",
    "#Group_data.apply(lambda x:print(x))\n",
    "normed_volatility=(lookahead_volatility-np.mean(lookahead_volatility))/(np.std(lookahead_volatility))\n",
    "#normed_volatility=(lookahead_volatility-np.min(lookahead_volatility))/(np.max(lookahead_volatility)-np.min(lookahead_volatility))\n",
    "#normed_volatility=lookahead_volatility\n",
    "print(normed_volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1585, 10, 4)\n",
      "(1585,)\n",
      "(1, 10, 4)\n",
      "[[[0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]\n",
      "  [0.595407   0.59521703 0.59560509 0.59541197]]]\n"
     ]
    }
   ],
   "source": [
    "def get_train_set(X,Y):\n",
    "    Xs=[]\n",
    "    for name, group in X:\n",
    "        cur_X=group[[\"Open\",\"High\",\"Low\",\"Close\"]].iloc[230:240]\n",
    "        cur_X_array=np.array(cur_X)\n",
    "        cur_X_list=cur_X_array.tolist()\n",
    "        #print(cur_X_list)\n",
    "        Xs.append(cur_X_list)\n",
    "    Xs.pop()#将2012/9/7的数据去掉。我们先试图预测一下2012/9/6的波动率。\n",
    "    return np.array(Xs), np.array(Y)\n",
    "x,y=get_train_set(Group_data, normed_volatility)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x_train, x_test=x[:int(len(x) * .9)],x[int(len(x) * .9):-1]\n",
    "y_train, y_test=y[:int(len(y) * .9)],y[int(len(y) * .9):-1]\n",
    "#实际上我们得到的数据是今天的价格对应明天的波动率，一直到2012/9/5。事实上这是9-6的输入和输出。\n",
    "#这里留下最后一行作为预测项。我们希望预测9-7，输入9-6的价格数据，得出9-7的波动率。\n",
    "x_unknown=x[[-1]]#这是表格上2012/9/6对应的价格数据，实际上是9-7应该的输入，我们估计9-7的波动率。\n",
    "print(x_unknown.shape)\n",
    "Y_test=normed_volatility[int(len(x)* .9):]#以DataFrame格式存储以便后面可以调用索引。\n",
    "print(x_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Permute, RepeatVector\n",
    "from keras.layers import Merge, Input, concatenate\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, AtrousConvolution1D\n",
    "from keras.layers.pooling import AveragePooling1D, MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "from keras.constraints import *\n",
    "from keras import regularizers\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= .5\n",
    "_data_shape = (10, 4)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(LSTM(128, input_shape=_data_shape, return_sequences=False))\n",
    "#model.add(Dropout(d))#d=0.5前面指出了\n",
    "model.add(Dense(16, kernel_initializer=('uniform'),activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='tanh'))\n",
    "\n",
    "opt=Nadam(lr=0.02, clipnorm= .1)\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "#存储模型\n",
    "checkpointer=ModelCheckpoint(monitor='val_loss',filepath='/Users/tangfuyu/Desktop/code/volatility/model_save1/model_returns.hdf5',verbose=1, save_best_only=True)\n",
    "#训练模型\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_data_shape = (10, 4)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=_data_shape, return_sequences=False))\n",
    "model.add(Dense(16, kernel_initializer=('uniform'),activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='tanh'))\n",
    "model.compile(optimizer=opt, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_fit是正式开始迭代数据\n",
    "history=model.fit(\n",
    "    x_train,#data\n",
    "    y_train,#labels\n",
    "    batch_size=60,#是批梯度下降和随机梯度下降的折中方法，将样本数据分为若干批。batch_size是个数。\n",
    "    epochs=10,#样本中的所有数据被计算一次就是一个epochs\n",
    "    validation_split=0.1,\n",
    "    callbacks=[reduce_lr,checkpointer],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型预测\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "model.load_weights(\"/Users/tangfuyu/Desktop/experiment/pyexperiment/volatility/model_save1/model_returns.hdf5\")\n",
    "y_pred=model.predict(x_test)\n",
    "pred_df = pd.DataFrame(np.column_stack([y_test, y_pred]),columns=[\"y_test\",\"y_pred\"])\n",
    "print(pred_df)\n",
    "pred_df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在9-7输入9-6的价格数据来获取9-7的波动率。\n",
    "y_unknown=model.predict(x_unknown)\n",
    "print(y_unknown)\n",
    "normed_predict_volatility=y_unknown[0][0]\n",
    "predict_volatility=normed_predict_volatility*np.std(lookahead_volatility)+np.mean(lookahead_volatility)\n",
    "print(predict_volatility)\n",
    "#用2012-9-6的价格序列预测2012-9-7的波动率。实际上是2012-9-6天末到2012-9-7天末的波动率估计。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取每日最高价\n",
    "high=df[\"High\"].groupby(\"Date\").max()\n",
    "high.name=\"High\"\n",
    "print(high.shape)\n",
    "#获取每日最低价\n",
    "low=df[\"Low\"].groupby(\"Date\").min()\n",
    "low.name=\"Low\"\n",
    "print(low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以词典形式存储对应的开盘价和收盘价再转成dataframe的形式\n",
    "Open_Dict={}\n",
    "Close_Dict={}\n",
    "for name, group in df[\"Open\"].groupby(\"Date\"):\n",
    "    Open_Dict[name]=group.iloc[0]\n",
    "for name, group in df[\"Close\"].groupby(\"Date\"):\n",
    "    Close_Dict[name]=group.iloc[239]\n",
    "Open=pd.DataFrame.from_dict(Open_Dict, orient='index')\n",
    "Close=pd.DataFrame.from_dict(Close_Dict, orient='index')\n",
    "#这里形成的历史数据和前面需要的训练数据不同。这里形成的是每日的价格和对应的波动率。\n",
    "history_data=pd.concat([Open,high,low,Close,volatility],axis=1).dropna()\n",
    "history_data.columns=['Open','High','Low','Close','today_volatility']\n",
    "history=history_data.drop([\"2012/9/7\"])\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#从9-6开始我们已经得到了9月7号的估计波动率。实际上是指从9月6号结束到9月7号结束这一段时间内的波动率。\n",
    "#取包括2012-9-6往前的500个场景来统计变化。\n",
    "def get_change(dataframe,future_volatility):#要求参数为dataframe\n",
    "    Values=[]\n",
    "    Values_change=[]\n",
    "    now_value=dataframe.iloc[-1][\"Close\"]#是9-6的收盘价\n",
    "    print(now_value)\n",
    "    for i in range(len(dataframe)-500,len(dataframe),1):#得出500个变化场景。\n",
    "        after_change=dataframe.iloc[i][\"Close\"]\n",
    "        before_change=dataframe.iloc[i-1][\"Close\"]\n",
    "        volatility_before=dataframe.iloc[i][\"today_volatility\"]\n",
    "        multiple=before_change+(after_change-before_change)*future_volatility/volatility_before\n",
    "        value=now_value*multiple/before_change\n",
    "        Values.append(value)\n",
    "        value_change=value-now_value\n",
    "        Values_change.append(value_change)\n",
    "    return Values, Values_change\n",
    "\n",
    "\n",
    "Values,Values_change=get_change(history,predict_volatility)\n",
    "print(len(Values))\n",
    "print(type(Values_change))\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对500个场景进行排序，在1天展望时期以及99%的置信区间下，对应于第5个最糟糕的情形\n",
    "Values_change.sort()\n",
    "print(Values_change)\n",
    "VaR=Values_change[4]\n",
    "print(VaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
